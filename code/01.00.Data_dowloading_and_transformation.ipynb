{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Downloading and transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Goals**\n",
    "1. Retrive data from boldsystems.\n",
    "2. Transform the xml files to text files (.tsv).\n",
    "3. Build FASTA format sequnces from the text files.\n",
    "4. Retriving unpublished data from the BOLDSystems and reformating the headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Retriving data from boldsystems**\n",
    "Using the boldsystemsV4 [PUBLIC DATA API](http://www.boldsystems.org/index.php/resources/api?type=webservices) to export **Full Data Retrieval (Specimen + Sequence)** from a list of countries stored in a file (named by country) in a default destination directory \"co1_metaanalysis/data/input/input_data/bold_africa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bolddata_retrival() { # This fuction retrives data belonging to a list of country names given. Input can be a file containing names of select countries or idividual country names\n",
    "        if [[ ( $# -eq 0 ) || ! ( `echo $1` =~ -.*$ ) ]]\n",
    "        then\n",
    "                echo \"Input error...\"\n",
    "                echo \"function usage: ${FUNCNAME[0]} [-a] [-c <name of country>] [-f <a file with list of countries and named *countries*>]\"\n",
    "                return 1\n",
    "        fi\n",
    "\n",
    "        local OPTIND=1\n",
    "        countries=()\n",
    "\n",
    "        while getopts 'ac:f:' key\n",
    "        do\n",
    "                case \"${key}\" in\n",
    "                        f)\n",
    "                                if [ ! -f $OPTARG ]\n",
    "                                then\n",
    "                                        echo \"input error: file $OPTARG is non-existent!\"\n",
    "                                elif [[ ( -f $OPTARG ) && ( `basename $OPTARG` =~ ^.*countries.*$ ) ]]\n",
    "                                then\n",
    "                                        countries+=(\"$(while IFS=\"\\n\" read -r line || [[ \"$line\" ]]; do geography+=(\"`echo $line | sed 's/ /%20/g'`\"); done < $OPTARG)\")\n",
    "                                else\n",
    "                                        echo \"input file error in `basename $OPTARG`: input file should be named '.*countries.*'\"\n",
    "                                fi\n",
    "                                ;;\n",
    "                        c)\n",
    "                                countries+=(`echo $OPTARG | sed 's/ /%20/g'`)\n",
    "                                ;;\n",
    "                        a)\n",
    "                                countries=(\"all\")\n",
    "                                ;;\n",
    "                        ?)\n",
    "                                echo \"Input error...\"\n",
    "                                echo \"function usage: ${FUNCNAME[0]} [-a] [-c <name of country>] [-f <a file with list of countries>]\"\n",
    "                                return 1\n",
    "                                ;;\n",
    "                esac\n",
    "        done\n",
    "\n",
    "        echo -e \"\\n\\tDownloading data of countries named in ${countries[@]} from www.boldsystems.org V4\"\n",
    "        unset taxon_nam\n",
    "        regexp='^[a-zA-Z0-9/_-\\ ]+$'\n",
    "\n",
    "        until [[ \"$taxon_nam\" =~ $regexp ]]\n",
    "        do\n",
    "                read -p \"Please enter taxon name to be searched, ensure the spelling is right otherwise you get everything downloaded. To ensure that you are downloading the right dataset first go to 'http://v4.boldsystems.org/index.php/Public_BINSearch?searchtype=records' and search the tax(on|a) of choice as explained:: \" taxon_nam\n",
    "        done\n",
    "\n",
    "        taxon_name=`echo $taxon_nam | sed 's/ /%20/g'`\n",
    "\n",
    "        wgetoutput_dir=${inputdata_path}bold_data/${taxon_name}\n",
    "        until [[ -d ${wgetoutput_dir} ]]\n",
    "        do\n",
    "                echo \"Creating output directory '${wgetoutput_dir}'\"\n",
    "                mkdir ${wgetoutput_dir}\n",
    "        done\n",
    "\n",
    "        IFS=$'\\n'\n",
    "        if [[ ! ( `echo ${countries[0]}` =~ \"all\" ) ]]\n",
    "        then\n",
    "                for i in ${countries[@]}\n",
    "                do\n",
    "                        wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${i}\"_summary.xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/stats?geo=${i}&taxon=${taxon_name}&format=xml\"\n",
    "                        #wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${i}\"_specimen.xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/specimen?geo=${i}&taxon=${taxon_name}&format=xml\"\n",
    "                        wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${i}\".xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/combined?geo=${i}&taxon=${taxon_name}&format=xml\"\n",
    "                done\n",
    "        elif [[ ( `echo ${countries[0]}` =~ \"all\" ) ]]\n",
    "        then\n",
    "                wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${taxon_nam}\"_summary.xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/stats?taxon=${taxon_name}&format=xml\"\n",
    "                #wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${taxon_nam}\"_specimen.xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/specimen?taxon=${taxon_name}&format=xml\"\n",
    "                wget --show-progress --progress=bar:noscroll --retry-connrefused -t inf -O ${wgetoutput_dir}/\"${taxon_nam}\".xml -a ${wgetoutput_dir}/${taxon_nam}_wget_log \"http://www.boldsystems.org/index.php/API_Public/combined?taxon=${taxon_name}&format=xml\"\n",
    "        fi\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error...\n",
      "function usage: bolddata_retrival [-a] [-c <name of country>] [-f <a file with list of countries and named *countries*>]\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\\nsource ./process_all_input_files.sh\\nbolddata_retrival #-c country  #Uncomment the word \"country\" to download from a list of countries in the file country (canada)\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc65f2ce35e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\\nsource ./process_all_input_files.sh\\nbolddata_retrival #-c country  #Uncomment the word \"country\" to download from a list of countries in the file country (canada)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-109>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\\nsource ./process_all_input_files.sh\\nbolddata_retrival #-c country  #Uncomment the word \"country\" to download from a list of countries in the file country (canada)\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\n",
    "source ./process_all_input_files.sh\n",
    "bolddata_retrival #-c country  #Uncomment the word \"country\" to download from a list of countries in the file country (canada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Transformation of the XML files to tsv**\n",
    "Here we use python3 packages : **BeautifulSoup4** and **pandas**.  \n",
    "(**N/B:** Tried using R ([01.02.R_xml_to_tsv.ipynb](./01.02.R_xml_to_tsv.ipynb)), but didn't work well)  \n",
    "For more on the logic behind the extraction script see jupyter notebook [01.01.xml_to_tsv.ipynb](./01.01.xml_to_tsv.ipynb)  \n",
    "The country specific XML files are converted to text (.tsv) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "boldxml2tsv() { #This function generates .tsv files from .xml files using python script and Beautifulsoup4 and pandas package\n",
    "\n",
    "        usage $@\n",
    "\n",
    "        TAB=$(printf '\\t')\n",
    "\n",
    "        echo \"generating .tsv files from .xml downloads\"\n",
    "\n",
    "        for i in \"$@\"\n",
    "        do\n",
    "                if [ ! -f $i ]\n",
    "                then\n",
    "                        echo \"input error: file '$i' is non-existent!\"\n",
    "                elif [[ ( -f $i ) && ( `basename -- \"$i\"` =~ .*\\.(xml) ) ]]\n",
    "                then\n",
    "                        rename\n",
    "                        echo -e \"\\nLet us proceed with file '${input_filename}'...\"\n",
    "                        sed 's/class/Class/g' \"$i\" | sed \"s/$TAB/,/g\" > ${inputdata_path}bold_africa/input.xml\n",
    "                        ${PYTHON_EXEC} ${xml_to_tsv} ${inputdata_path}bold_africa/input.xml && mv output.tsv ${inputdata_path}bold_africa/${output_filename}.tsv\n",
    "                else\n",
    "                        echo \"input file error in `basename -- '$i'`: input file should be a .xml file format\"\n",
    "                        continue\n",
    "                fi\n",
    "        done\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error...\n",
      "Usage: build_tsv file1.*[file2.* file3.* ...]\n",
      "generating .tsv files from .xml downloads\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\n",
    "source ./process_all_input_files.sh\n",
    "boldxml2tsv #../data/input/input_data/bold_africa/kenya.xml  #Uncomment the path to execute the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the outcome of conversion of xml files to text (tsv) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1213 Algeria.tsv\n",
      "     1329 Angola.tsv\n",
      "      941 Benin.tsv\n",
      "      669 Botswana.tsv\n",
      "      301 Burkina_Faso.tsv\n",
      "      257 Burundi.tsv\n",
      "     7268 Cameroon.tsv\n",
      "      692 Cape_Verde.tsv\n",
      "     3487 Central_African_Republic.tsv\n",
      "       46 Chad.tsv\n",
      "     1400 Comoros.tsv\n",
      "      746 Cote_d_Ivoire.tsv\n",
      "     7580 Democratic_republic_of_the_Congo.tsv\n",
      "      472 Djibouti.tsv\n",
      "    20984 Egypt.tsv\n",
      "      479 Equatorial_Guinea.tsv\n",
      "       31 Eritrea.tsv\n",
      "     3792 Ethiopia.tsv\n",
      "    16898 Gabon.tsv\n",
      "      138 Gambia.tsv\n",
      "     4178 Ghana.tsv\n",
      "      100 Guinea-Bissau.tsv\n",
      "     1035 Guinea.tsv\n",
      "    29480 Kenya.tsv\n",
      "       68 Lesotho.tsv\n",
      "     2393 Liberia.tsv\n",
      "       93 Libya.tsv\n",
      "    50290 Madagascar.tsv\n",
      "     1899 Malawi.tsv\n",
      "      374 Mali.tsv\n",
      "      225 Mauritania.tsv\n",
      "     1736 Mauritius.tsv\n",
      "     5219 Morocco.tsv\n",
      "     2812 Mozambique.tsv\n",
      "     2449 Namibia.tsv\n",
      "     2876 Nigeria.tsv\n",
      "       75 Niger.tsv\n",
      "     2130 Republic_of_the_Congo.tsv\n",
      "     2038 Reunion.tsv\n",
      "      791 Rwanda.tsv\n",
      "      260 Sao_Tome_and_Principe.tsv\n",
      "     1487 Senegal.tsv\n",
      "     2270 Seychelles.tsv\n",
      "      309 Sierra_Leone.tsv\n",
      "      262 Somalia.tsv\n",
      "    74870 South_Africa.tsv\n",
      "       40 South_Sudan.tsv\n",
      "      183 Sudan.tsv\n",
      "      221 Swaziland.tsv\n",
      "    11016 Tanzania.tsv\n",
      "      265 Togo.tsv\n",
      "     2270 Tunisia.tsv\n",
      "     2186 Uganda.tsv\n",
      "     3213 Zambia.tsv\n",
      "     1407 Zimbabwe.tsv\n",
      "   279243 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/bold_africa/\n",
    "wc -l *.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Build FASTA sequences from the .tsv text files**\n",
    "The building of FASTA files is not done directly on the country specific text (.tsv) files.\n",
    "It is done after some cleaning and sorting.\n",
    "1. First only those with Insecta genus-name tag are extracted and all the records are cleaned of any non-COI-5P markers  \n",
    "2. Then ALL the records are re-grouped into subsets based on sequence length  \n",
    "3. Then fourteen 100-record samples are randomly sampled from this groups, to be used in the development and testing of the bioinformatics analysis pipelines  \n",
    "4. Finally the re-grouped subsets and the samples are converted to FASTA format sequences  \n",
    "\n",
    "There are two rscripts:  \n",
    "1. [data_cleanup_n_sampling.R](./data_cleanup_n_sampling.R): Meant for cleaning, sorting and sampling the test data (East African data: Kenya, Tanzania, Uganda, Rwanda, Burundi, Ethiopia and South Sudan).  \n",
    "See [02.00.Data_cleanup](./02.00.Data_cleanup.ipynb) for more information on step '1.' to '3.' \n",
    "2. [data_cleanup.R](./data_cleanup.R): Meant for cleaning and sorting all country specific records\n",
    "\n",
    "**To sort the data for all country specific records into the groups defined by sequence length do as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "append_tsvfile() { # this function tests if the .tsv file has content and if it does it appends it to a cummulative file of all input records. This function is applied in the function below: clean_sort_tsv()\n",
    "\n",
    "        if [ `grep -v \"X..bioinformatics\" ${input} | wc -l` -ge 1 ]\n",
    "        then\n",
    "                awk 'FNR==1 { while (/^X..bioinformatics/) getline; }   1 {print}' ${input} >> ${output}\n",
    "        else\n",
    "                echo -e \"\\n `basename -- $input` from `basename -- $i` has no content besides the header!!!\"\n",
    "        fi\n",
    "}\n",
    "\n",
    "\n",
    "clean_sort_tsv() { #This function cleans the .tsv files, sort the records into differnt files based on the sequence length and finally appends this files to a cummulative files of diffent input files\n",
    "\n",
    "        usage $@\n",
    "\n",
    "        echo \"cleaningup and sorting .tsv files \"\n",
    "\n",
    "        output_files_africa=(\"${inputdata_path}clean_africa/afroCOI_500to700_data.tsv\" \"${inputdata_path}clean_africa/afroCOI_650to660_data.tsv\" \"${inputdata_path}clean_africa/afroCOI_all_data.tsv\" \"${inputdata_path}clean_africa/afroCOI_Over499_data.tsv\" \"${inputdata_path}clean_africa/afroCOI_Over700_data.tsv\" \"${inputdata_path}clean_africa/afroCOI_Under500_data.tsv\")\n",
    "\n",
    "        output_files_eafrica=(\"${inputdata_path}clean_eafrica/eafroCOI_500to700_data.tsv\" \"${inputdata_path}clean_eafrica/eafroCOI_650to660_data.tsv\" \"${inputdata_path}clean_eafrica/eafroCOI_all_data.tsv\" \"${inputdata_path}clean_eafrica/eafroCOI_Over499_data.tsv\" \"${inputdata_path}clean_eafrica/eafroCOI_Over700_data.tsv\" \"${inputdata_path}clean_eafrica/eafroCOI_Under500_data.tsv\")\n",
    "\n",
    "\n",
    "        for i in ${output_files_africa[@]}\n",
    "        do\n",
    "                grep \"processid\" $1 > $i && echo -e \"\\nInput file $i is set\"\n",
    "        done\n",
    "\n",
    "        for i in ${output_files_eafrica[@]}\n",
    "        do\n",
    "                grep \"processid\" $1 > $i && echo -e \"\\nInput file $i is set\"\n",
    "        done\n",
    "\n",
    "\n",
    "        for i in \"$@\"\n",
    "        do\n",
    "                if [ ! -f $i ]\n",
    "                then\n",
    "                        echo \"input error: file '$i' is non-existent!\"\n",
    "                elif [[ ( -f $i ) && ( `basename -- \"$i\"` =~ .*\\.(tsv) ) ]]\n",
    "                then\n",
    "                        rename\n",
    "                        echo -e \"\\nLet us proceed with file '${input_filename}'...\"\n",
    "                        ${RSCRIPT_EXEC} --vanilla ${data_cleanup} $i\n",
    "\n",
    "                        case $output_filename in\n",
    "                                Algeria|Madagascar|Angola|Malawi|Benin|Mali|Botswana|Mauritania|Burkina_Faso|Mauritius|Morocco|Cameroon|Mozambique|Cape_Verde|Namibia|Central_African_Republic|Nigeria|Chad|Niger|Comoros|Republic_of_the_Congo|Cote_d_Ivoire|Reunion|Democratic_republic_of_the_Congo|Djibouti|Sao_Tome_and_Principe|Egypt|Senegal|Equatorial_Guinea|Seychelles|Eritrea|Sierra_Leone|Somalia|Gabon|South_Africa|Gambia|Ghana|Sudan|Guinea-Bissau|Swaziland|Guinea|Togo|Tunisia|Lesotho|Liberia|Zambia|Libya|Zimbabwe)\n",
    "                                        input=${inputdata_path}clean_africa/COI_500to700_data.tsv\n",
    "                                        output=${output_files_africa[0]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_650to660_data.tsv\n",
    "                                        output=${output_files_africa[1]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_all_data.tsv\n",
    "                                        output=${output_files_africa[2]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Over499_data.tsv\n",
    "                                        output=${output_files_africa[3]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Over700_data.tsv\n",
    "                                        output=${output_files_africa[4]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Under500_data.tsv\n",
    "                                        output=${output_files_africa[5]}\n",
    "                                        append_tsvfile\n",
    "                                        ;;\n",
    "                                Kenya|Tanzania|Uganda|Rwanda|Burundi|South_Sudan|Ethiopia)\n",
    "                                        input=${inputdata_path}clean_africa/COI_500to700_data.tsv\n",
    "                                        output=${output_files_eafrica[0]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_650to660_data.tsv\n",
    "                                        output=${output_files_eafrica[1]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_all_data.tsv\n",
    "                                        output=${output_files_eafrica[2]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Over499_data.tsv\n",
    "                                        output=${output_files_eafrica[3]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Over700_data.tsv\n",
    "                                        output=${output_files_eafrica[4]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        input=${inputdata_path}clean_africa/COI_Under500_data.tsv\n",
    "                                        output=${output_files_eafrica[5]}\n",
    "                                        append_tsvfile\n",
    "\n",
    "                                        ;;\n",
    "                                *)\n",
    "                                        echo -e \"The file $output_filename \\b.tsv is not in the list of African countries or is not in the right format.\"\n",
    "                                        ;;\n",
    "                        esac\n",
    "                 else\n",
    "                        echo \"input file error in `basename -- $i`: input file should be a .tsv file format\"\n",
    "                        continue\n",
    "                fi\n",
    "        done\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error...\n",
      "Usage: clean_sort_tsv file1.*[file2.* file3.* ...]\n",
      "cleaningup and sorting .tsv files \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/code/\n",
    "source ./process_all_input_files.sh\n",
    "clean_sort_tsv #../data/input_data/bold_africa/*.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorting rscript separates East African data from the rest of Africa and stores them in two separate directories: \"co1_metaanalysis/data/input/input_data/clean_eafrica\" and \"co1_metaanalysis/data/input/input_data/clean_africa\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To convert the .tsv files to FASTA format files do as follows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point to Note**  \n",
    "Please note that errors may occur especially in cases where in the original .xml file there is existennce of values within fields that have end of line break `\\n` or carriage return `\\r\\n`. In such cases extra editing will be required on the original .tsv files to substitute these end of line breaks with a white space. But this can only be done after a FASTA format sequence file is generated and each problematic end of line character, in this case a double `\\n\\n` identified and its' source corrected in the .tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "boldtsv2fasta() { #This function generates .fasta files from .tsv files using an awk script\n",
    "\n",
    "        usage $@\n",
    "\n",
    "        echo \"generating .fasta files from .tsv metadata files\"\n",
    "\n",
    "        for i in \"$@\"\n",
    "        do\n",
    "                if [ ! -f $i ]\n",
    "                then\n",
    "                        echo \"input error: file '$i' is non-existent!\"\n",
    "                elif [[ ( -f $i ) && ( `basename -- \"$i\"` =~ .*\\.(tsv) ) ]]\n",
    "                then\n",
    "                        input_src=`dirname \"$( realpath \"${i}\" )\"`\n",
    "                        rename\n",
    "                        echo -e \"\\nLet us proceed with file '${input_filename}'...\"\n",
    "                        ${AWK_EXEC} -f ${AWK_SCRIPT} \"$i\" > ${input_src}/${output_filename}.fasta\n",
    "                else\n",
    "                        echo \"input file error in `basename -- $i`: input file should be a .tsv file format\"\n",
    "                        continue\n",
    "                fi\n",
    "        done\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error...\n",
      "Usage: build_fasta file1.*[file2.* file3.* ...]\n",
      "generating .fasta files from .tsv metadata files\n",
      "Input error...\n",
      "Usage: build_fasta file1.*[file2.* file3.* ...]\n",
      "generating .fasta files from .tsv metadata files\n",
      "Input error...\n",
      "Usage: build_fasta file1.*[file2.* file3.* ...]\n",
      "generating .fasta files from .tsv metadata files\n",
      "\n",
      "East African data sets in 'clean_eafrica/':\n",
      "    74378 clean_eafrica/eafroCOI_500to700_data.fasta\n",
      "    36742 clean_eafrica/eafroCOI_500to700_data.tsv\n",
      "     1019 clean_eafrica/eafroCOI_500to700_data_undesired.fasta\n",
      "    48950 clean_eafrica/eafroCOI_650to660_data.fasta\n",
      "    23560 clean_eafrica/eafroCOI_650to660_data.tsv\n",
      "     1018 clean_eafrica/eafroCOI_650to660_data_undesired.fasta\n",
      "    76842 clean_eafrica/eafroCOI_all_data.fasta\n",
      "    38096 clean_eafrica/eafroCOI_all_data.tsv\n",
      "     1019 clean_eafrica/eafroCOI_all_data_undesired.fasta\n",
      "    75546 clean_eafrica/eafroCOI_Over499_data.fasta\n",
      "    37326 clean_eafrica/eafroCOI_Over499_data.tsv\n",
      "     1019 clean_eafrica/eafroCOI_Over499_data_undesired.fasta\n",
      "     5800 clean_eafrica/eafroCOI_Over700_data.fasta\n",
      "      585 clean_eafrica/eafroCOI_Over700_data.tsv\n",
      "     1540 clean_eafrica/eafroCOI_Under500_data.fasta\n",
      "      771 clean_eafrica/eafroCOI_Under500_data.tsv\n",
      "   424211 total\n",
      "\n",
      "African data sets in 'clean_africa/':\n",
      "    295356 clean_africa/afroCOI_500to700_data.fasta\n",
      "    147676 clean_africa/afroCOI_500to700_data.tsv\n",
      "    150458 clean_africa/afroCOI_650to660_data.fasta\n",
      "     75230 clean_africa/afroCOI_650to660_data.tsv\n",
      "    309530 clean_africa/afroCOI_all_data.fasta\n",
      "    154764 clean_africa/afroCOI_all_data.tsv\n",
      "    297474 clean_africa/afroCOI_Over499_data.fasta\n",
      "    148699 clean_africa/afroCOI_Over499_data.tsv\n",
      "      2046 clean_africa/afroCOI_Over700_data.fasta\n",
      "      1024 clean_africa/afroCOI_Over700_data.tsv\n",
      "     12130 clean_africa/afroCOI_Under500_data.fasta\n",
      "      6066 clean_africa/afroCOI_Under500_data.tsv\n",
      "   1600453 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/\n",
    "source ../../../code/process_all_input_files.sh\n",
    "build_fasta #../data/input/test_data/*.tsv # For test_data(East African data sets including their samples)\n",
    "build_fasta #../data/input/input_data/clean_africa/*.tsv # For re-grouped African data sets\n",
    "build_fasta #../data/input/input_data/clean_eafrica/*.tsv # For re-grouped East African data sets\n",
    "echo -e \"\\nEast African data sets in 'clean_eafrica/':\"\n",
    "wc -l clean_eafrica/eafroCOI*\n",
    "echo -e \"\\nAfrican data sets in 'clean_africa/':\"\n",
    "wc -l clean_africa/afroCOI*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorting rscript separates East African data from the rest of Africa and stores them in two separate directories: \"co1_metaanalysis/data/input/input_data/clean_eafrica\" and \"co1_metaanalysis/data/input/input_data/clean_africa\"  \n",
    "\n",
    "Below is the code to concatenate the the two different streams into one stored in \"co1_metaanalysis/data/input/input_data/clean_africa\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    295356 ./clean_africa/afroCOI_500to700_data.fasta\n",
      "    147676 ./clean_africa/afroCOI_500to700_data.tsv\n",
      "    150458 ./clean_africa/afroCOI_650to660_data.fasta\n",
      "     75230 ./clean_africa/afroCOI_650to660_data.tsv\n",
      "    309530 ./clean_africa/afroCOI_all_data.fasta\n",
      "    154764 ./clean_africa/afroCOI_all_data.tsv\n",
      "    297474 ./clean_africa/afroCOI_Over499_data.fasta\n",
      "    148699 ./clean_africa/afroCOI_Over499_data.tsv\n",
      "      2046 ./clean_africa/afroCOI_Over700_data.fasta\n",
      "      1024 ./clean_africa/afroCOI_Over700_data.tsv\n",
      "     12130 ./clean_africa/afroCOI_Under500_data.fasta\n",
      "      6066 ./clean_africa/afroCOI_Under500_data.tsv\n",
      "    170314 ./clean_africa/enafroCOI_500to700_data-650to660.fasta\n",
      "    369710 ./clean_africa/enafroCOI_500to700_data.fasta\n",
      "    199396 ./clean_africa/enafroCOI_650to660_data.fasta\n",
      "    386352 ./clean_africa/enafroCOI_all_data.fasta\n",
      "    385706 ./clean_africa/enafroCOI_all_data_raw.fasta\n",
      "    279189 ./clean_africa/enafroCOI_all_data_raw.tsv\n",
      "    372916 ./clean_africa/enafroCOI_Over499_data.fasta\n",
      "      3214 ./clean_africa/enafroCOI_Over700_data.fasta\n",
      "     13430 ./clean_africa/enafroCOI_Under500_data.fasta\n",
      "   3780680 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/\n",
    "#cat ./clean_africa/afroCOI_500to700_data.fasta ./clean_eafrica/eafroCOI_500to700_data.fasta > ./clean_africa/enafroCOI_500to700_data.fasta\n",
    "#cat ./clean_africa/afroCOI_650to660_data.fasta ./clean_eafrica/eafroCOI_650to660_data.fasta > ./clean_africa/enafroCOI_650to660_data.fasta\n",
    "#cat ./clean_africa/afroCOI_all_data.fasta ./clean_eafrica/eafroCOI_all_data.fasta > ./clean_africa/enafroCOI_all_data.fasta\n",
    "#cat ./clean_africa/afroCOI_Over499_data.fasta ./clean_eafrica/eafroCOI_Over499_data.fasta > ./clean_africa/enafroCOI_Over499_data.fasta\n",
    "#cat ./clean_africa/afroCOI_Over700_data.fasta ./clean_eafrica/eafroCOI_Over700_data.fasta > ./clean_africa/enafroCOI_Over700_data.fasta\n",
    "#cat ./clean_africa/afroCOI_Under500_data.fasta ./clean_eafrica/eafroCOI_Under500_data.fasta > ./clean_africa/enafroCOI_Under500_data.fasta\n",
    "wc -l ./clean_africa/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a file called **\"enafroCOI_500to700_data-650to660.fasta\"** of sequences with nucleotide number from 500 to 700, but excluding those with 650 to 660 nucleotides represented in enafroCOI_650to660_data.fasta  \n",
    "Uses a fuctions in a bash script, \"process_all_input_files.sh\", that does the necessary text processing needed.  \n",
    "See the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "delete_repeats() { #This function takes a fasta_format_sequences file and deletes repeats of sequences based on identical headers.\n",
    "        #in multiple files at once: awk -F'[|]' 'FNR%2{f=seen[$1]++} !f' *\n",
    "        #in each file: awk -F'[|]' 'FNR==1{delete seen} FNR%2{f=seen[$1]++} !f' *\n",
    "        if [ $# -eq 0 ]\n",
    "        then\n",
    "                echo \"Input error...\"\n",
    "                echo \"Usage: ${FUNCNAME[0]} file1.*[file2.* file3.* ...]\"\n",
    "                return 1\n",
    "        fi\n",
    "\n",
    "        for i in \"$@\"\n",
    "        do\n",
    "                rename\n",
    "                input_src=`dirname \"$( realpath \"${i}\" )\"`\n",
    "                unset duplicate_headers\n",
    "                duplicate_headers=`grep \">\" $i | $AWK_EXEC 'BEGIN { FS=\"|\"; }; {print $1; }' | sort | uniq -d`\n",
    "                if [ ! -z \"$duplicate_headers\" ]\n",
    "                then\n",
    "                        echo -e \"\\t`echo -e \"$duplicate_headers\" | wc -l` records are repeated in $i,\\n\\twould you like to proceed and delete all repeats?\"\n",
    "                        read -p \"Please enter [Yes] or [No] to proceed: \" choice\n",
    "                else\n",
    "                        choice=\"No\"\n",
    "                fi\n",
    "                case $choice in\n",
    "                        YES|Yes|yes|Y|y)\n",
    "                                concatenate_fasta_seqs $i\n",
    "                                $AWK_EXEC -F'[>|]' 'FNR==1{delete seen} FNR%2{f=seen[$2]++} !f' $i > ${input_src}/${output_filename}_cleaned && mv ${input_src}/${output_filename}_cleaned $( realpath \"${i}\" )\n",
    "                                echo -e \"\\tDuplicate records deleted\\n\"\n",
    "                                ;;\n",
    "                        No|NO|no|N|n)\n",
    "                                if [ ! -z \"$duplicate_headers\" ]\n",
    "                                then\n",
    "                                        echo -e \"\\tWould you like to save a list of the dublicates?\"\n",
    "                                        read -p \"Please enter [Yes] or [No] to proceed: \" option\n",
    "                                        case $option in\n",
    "                                                YES|Yes|yes|Y|y)\n",
    "                                                        echo -e \"\\tCancelling....\\nThe list of repeated sequences is in file called '_duplicates'\\n\"\n",
    "                                                        echo -e \"$duplicate_headers\" > ${input_src}/${output_filename}_duplicates\n",
    "                                                        ;;\n",
    "                                                No|NO|no|N|n)\n",
    "                                                        echo -e \"\\tCancelling...\\n\"\n",
    "                                                        ;;\n",
    "                                                *)\n",
    "                                                        echo \"ERROR!!! Invalid selection\"\n",
    "                                                        ;;\n",
    "                                        esac\n",
    "                                else\n",
    "                                        echo -e \"\\tNo duplicate records in $i\\n\"\n",
    "                                fi\n",
    "                                ;;\n",
    "                        *)\n",
    "                                echo \"ERROR!!! Invalid selection\"\n",
    "                                ;;\n",
    "                esac\n",
    "        done\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/\n",
    "source ./process_all_input_files.sh\n",
    "cat enafroCOI_650to660_data.fasta enafroCOI_500to700_data.fasta > #input\n",
    "delete_repeats input\n",
    "x=`wc -l enafroCOI_650to660_data.fasta`\n",
    "awk -v x=$x `{if (NRF<=x) {next} else {print $0} }`./input > #enafroCOI_500to700_data-650to660.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Retriving unpublished data from the BOLDSystems and reformating the headers**\n",
    "#### **4.1 To retrive unpublished data from [BOLD Systems](http://www.boldsystems.org/index.php/MAS_Management_UserConsole)**, first create a [BOLD systems account](http://www.boldsystems.org/index.php/MAS_Management_NewUserApp), [login](http://www.boldsystems.org/index.php/Login/page?destination=MAS_Management_UserConsole) and request data managers, to share their data sets.  \n",
    "My list of shared data sets are:\n",
    "1. [DS-KENFRUIT](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=DS-KENFRUIT): managed by Dr Scott E. Miller, has 1,427 records  \n",
    "2. [DS-MPALALEP](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=DS-MPALALEP): managed by Dr Scott E. Miller, has 2,472 records  \n",
    "3. [DS-TBILE](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=DS-TBILE) (Now publicly released now): managed by Dr Scott E. Miller has 90 records  \n",
    "\n",
    "My list of container Projects; these contains multiple data sets within them:\n",
    "4. [IDRCK](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=IDRCK): Has a number of subprojects; IDRC,HIVE, KBIR, KALG, KFISH, KPLA, ARAK and KINS. Has 2,110 sequences (COI-5P=1,704, matK=139, rbcLa=267) out of 6,016 specimen and is managed by Dr. Daniel Masiga.  \n",
    "5. [GMTAH](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=GMTAH),[GMTAI](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=GMTAI) and [GMTAJ](http://www.boldsystems.org/index.php/MAS_Management_DataConsole?codes=GMTAJ) projects. All under the Global Malaise Program and the three have a combined total of 60 Projects and 49246 Specimens.  \n",
    ">1. GMTAH: Has 26 projects titled \"Kenya Malaise Mpala 2014\" with 25,514 specimen, 170 species and 21,742 sequences (COI-5P=21,737, 28S=4 and EF1-alpha=1)  \n",
    ">2. GMTAI: Has 26 projects titled \"Kenya Malaise Kinondo 2014\" with 13,656 specimen, 57 species and 11,805 sequences (COI-5P=11,801, 28S=3 and EF1-alpha=1)  \n",
    ">3. GMTAJ: Has 5 projects titled \"Kenya Malaise Turkana 2014\" with 10,076 specimen, 63 species and 5,175 sequences (COI-5P=5,175)  \n",
    "\n",
    "To retrive this data, I logged into the [BOLD Systems MAS management interface](http://www.boldsystems.org/index.php/MAS_Management_UserConsole) through Chromium web browser and for each named project above: DS-KENFRUIT, DS-MPALALEP, DS-TBILE, IDRCK AND GMTAH-GMTAI-GMTAJ (Mpala_Kinondo_Turkana_Malaise_traps), downloaded the spreadsheet and the sequence files to \"/co1_metaanalysis/data/input/input_data/unpublished\" directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS-KENFRUIT.fasta\n",
      "DS-KENFRUIT_headers\n",
      "DS-KENFRUIT.xlsx\n",
      "DS-MPALALEP.fasta\n",
      "DS-MPALALEP_headers\n",
      "DS-MPALALEP.xlsx\n",
      "headers_edit.fasta\n",
      "idrck.fasta\n",
      "idrck_headers\n",
      "idrck_headers_all\n",
      "idrck_headers.csv\n",
      "idrck_orders\n",
      "idrck.xls\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.fasta\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.fasta2\n",
      "Mpala_Kinondo_Turkana_Malaise_traps_unedited.fasta\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.xlsx\n",
      "Mpala_Kinondo_Turkana_tagged.xlsx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Changing the headers to look uniform to other headers**  \n",
    "Current headers look like:\n",
    ">\\>PMANL5032-15|Sarrothripini|Arthropoda|Insecta|Lepidoptera|Nolidae|Chloephorinae|Sarrothripini||||Kenya|Muhaka Forest|-4.325|39.525|50.0  \n",
    ">\\>PMANL5022-15|Lobesia vanillana|Arthropoda|Insecta|Lepidoptera|Tortricidae|Olethreutinae||Lobesia|Lobesia vanillana||Kenya|Muhaka Forest|-4.325|39.525|50.0  \n",
    "\n",
    "To an edited header that looks like:\n",
    ">\\>PMANL5032-15|Arthropoda|Insecta|Lepidoptera|fam-Nolidae|subfam-Chloephorinae|tri-Sarrothripini|gs-NA|sp-NA|subsp-NA|country-Kenya|exactsite-Muhaka_Forest|lat_-4.325|lon_39.525|elev-50.0  \n",
    ">\\>PMANL5022-15|Arthropoda|Insecta|Lepidoptera|fam-Tortricidae|subfam-Olethreutinae|tri-NA|gs-Lobesia|sp-Lobesia_vanillana|subsp-NA|country-Kenya|exactsite-Muhaka_Forest|lat_-4.325|lon_39.525|elev-50.0  \n",
    "\n",
    "This standardizes the headers to a common format that is useful in the downstream analysis.  \n",
    "For this to be done the headers of a given sequence file are first copied into a file, headers_edit.fasta, within which they are edited to the right format i.e:  \n",
    "1. Deleting the default taxon (e.g Sarrothripini, in the first example) automatically assigned by BOLD systems during the download process which is usually the lowest taxon defined in the taxonomy of that record. This appears in the header just right after the unique identifier/process ID. \n",
    "2. Defining the various fields of the headers by adding suffices; fam-\"family\", subfam-\"subfamily\", tri-\"tribe\", gs-\"genus\", sp-\"species\", subsp-\"subspecies\", country-\"country\", exactsite-\"exact site\", lat_\"latitude\", lon_\"longitude\" and elev_\"elevation\".  \n",
    "\n",
    "Then the formated headers are substituted into the actual sequence.fasta file using a function, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "replacing_headers() { #This function takes an input file of edited_fasta_format_headers and searches through a fasta_format_sequence file and substitute it's headers if their uniq IDs match\n",
    "        if [ $# -eq 0 ]\n",
    "        then\n",
    "                echo \"Input error...\"\n",
    "                echo \"Usage: ${FUNCNAME[0]} seq.fasta [seq2.fasta seq3.fasta ...]\"\n",
    "                return\n",
    "        fi\n",
    "\n",
    "        unset headers\n",
    "        until [[ ( -f \"$headers\" ) && ( `basename -- \"$headers\"` =~ .*_(fasta|fa|afa) ) ]]\n",
    "        do\n",
    "                echo -e \"\\nFor the headers_[aln|fasta|fa|afa] input provide the full path to the file, the filename included.\"\n",
    "                read -p \"Please enter the file to be used as the FASTA headers source: \" headers\n",
    "                #$.*/[\\]'^\n",
    "                sed -i \"s/\\r$//g; s/ /_/g; s/\\&/_n_/g; s/\\//+/g; s/'//g; s/\\[//g; s/\\]//g\" $headers\n",
    "        done\n",
    "\n",
    "        echo -e \"\\n\\tStarting operation....\\n\\tPlease wait, this may take a while....\"\n",
    "        for i in \"$@\"\n",
    "        do\n",
    "                unset records\n",
    "                number_of_replacements=0\n",
    "                records=$( grep \">\" $i | wc -l )\n",
    "                unset x\n",
    "                unset y\n",
    "                unset z\n",
    "                echo -e \"\\nProceeding with `basename -- $i`...\"\n",
    "                for line in `cat ${headers}`\n",
    "                do\n",
    "                        #x=$( head -10 idrck_headers | tail -1 | awk 'BEGIN { FS=\"|\"; }{print $1;}') && echo $x\n",
    "                        x=`echo \"$line\" | ${AWK_EXEC} 'BEGIN { RS=\"\\n\"; FS=\"|\"; }{ x = $1; print x; }'`\n",
    "                        y=`echo \"$line\" | ${AWK_EXEC} 'BEGIN { RS=\"\\n\"; FS=\"|\"; }{ y = $0; print y; }'`\n",
    "                        #echo -e \"\\n $x \\n $y\"\n",
    "\n",
    "                        #Characters to replace from the headers as they will affect the performance of sed: carriage Returns (^M), white spaces ( ), back slashes (/), and ampersand '&' characters; they greately hamper the next step of header substitution.\n",
    "                        sed -i \"s/\\r$//g; s/ /_/g; s/\\&/_n_/g; s/\\//+/g; s/'//g; s/\\[//g; s/\\]//g\" $i\n",
    "\n",
    "                        z=`grep \"$x\" $i`\n",
    "                        #echo \"$z\"\n",
    "                        for one_z in `echo -e \"${z}\"`\n",
    "                        do\n",
    "                                if [ $one_z == $y ]\n",
    "                                then\n",
    "                                        echo -e \"Change for ${x} already in place...\"\n",
    "                                        continue\n",
    "                                else\n",
    "                                        echo -e \"Substituting header for ${x}...\"\n",
    "                                        sed -i \"s/${one_z}/${y}/g\" $i\n",
    "                                        #sed -i \"s/^.*\\b${x}\\b.*$/${y}/g\" $i\n",
    "                                fi\n",
    "                                number_of_replacements=$( expr $number_of_replacements + 1 )\n",
    "                        done\n",
    "                done\n",
    "                echo -e \"\\nDONE. $number_of_replacements replacements done in `basename -- $i` out of $records records it has\"\n",
    "        done\n",
    "        echo -e \"\\n\\tCongratulations...Operation done.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.1 Working on idrck_headers.csv**\n",
    "A single spreadsheet file (.xls) was retrived from [BOLDSystems Version 3](http://v3.boldsystems.org/) ([-Version 4](http://www.boldsystems.org/) proofed unworkable-) for these dataset: Contains all record information from which the headers were built from.  \n",
    "Copy pasted the necessary columns (\"Process ID\", \"Phylum\", \"Class\", \"Order\", \"Family\",  \"Subfamily\", \"Tribe\", \"Genus\", \"Species\", \"Subspecies\", \"Country/Ocean\", \"Exact Site\", \"Lat\", \"Lon\", \"Elev\") into a single spreadsheet, then \"find&Replaced\" all \",\" with \"--\" and saved it in text format i.e CSV -Comma separated values-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idrck_headers.csv\n",
      "\"Process ID\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Subfamily\",\"Tribe\",\"Genus\",\"Species\",\"Subspecies\",\"Country/Ocean\",\"Exact Site\",\"Lat\",\"Lon\",\"Elev\"\n",
      "\"KALG100-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Acanthophora\",\"Acanthophora spicifera\",,\"Kenya\",,-4.26,39.599,\n",
      "\"KALG099-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Acanthophora\",\"Acanthophora spicifera\",,\"Kenya\",,-4.26,39.599,\n",
      "\"KALG098-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Acanthophora\",\"Acanthophora spicifera\",,\"Kenya\",,-4.26,39.599,\n",
      "\"KALG097-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Acanthophora\",\"Acanthophora spicifera\",,\"Kenya\",,-4.26,39.599,\n",
      "\"KALG096-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Acanthophora\",\"Acanthophora spicifera\",,\"Kenya\",,-4.26,39.599,\n",
      "\"KALG141-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Bostrychia\",\"Bostrychia radicans\",,\"Kenya\",,-3.944,39.774,\n",
      "\"KALG142-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Bostrychia\",\"Bostrychia radicans\",,\"Kenya\",,-3.944,39.774,\n",
      "\"KALG143-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Bostrychia\",\"Bostrychia radicans\",,\"Kenya\",,-3.944,39.774,\n",
      "\"KALG144-10\",\"Rhodophyta\",\"Florideophyceae\",\"Ceramiales\",\"Rhodomelaceae\",,,\"Bostrychia\",\"Bostrychia radicans\",,\"Kenya\",,-3.944,39.774,\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "ls *.csv\n",
    "head -10 idrck_headers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Headers**  \n",
    "All string are saved with a '\"' delimiter in the .csv format. This delimiter is removed with the command `sed -i 's/\"//g' idrck_headers.csv` shown below. The FASTA format headers are then generated using the command `awk 'BEGIN{FS=\",\"; OFS=\"|\"}; NR == 1 { next }; { for(i=1; i<=NF; i++) if($i ~ /^ *$/) $i = \"NA\" }; {print \">\" $1, $2, $3, $4, \"fam-\"$5, \"subfam-\"$6, \"tri-\"$7, \"gs-\"$8, \"sp-\"$9, \"subsp-\"$10, \"country-\"$11, \"exactsite-\"$12, \"lat_\"$13, \"lon_\"$14, \"elev-\"$15}' idrck_headers.csv > idrck_headers.fasta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idrck.fasta\n",
      "idrck_headers\n",
      "idrck_headers1.csv\n",
      "idrck_headers_all\n",
      "idrck_headers.csv\n",
      "idrck_headers.fasta\n",
      "idrck_headers.ods\n",
      "idrck_orders\n",
      "idrck.xls\n",
      ">KALG100-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      ">KALG099-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      ">KALG098-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      ">KALG097-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      ">KALG096-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      ">KALG141-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Bostrychia|sp-Bostrychia radicans|subsp-NA|country-Kenya|exactsite-NA|lat_-3.944|lon_39.774|elev-NA\n",
      ">KALG142-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Bostrychia|sp-Bostrychia radicans|subsp-NA|country-Kenya|exactsite-NA|lat_-3.944|lon_39.774|elev-NA\n",
      ">KALG143-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Bostrychia|sp-Bostrychia radicans|subsp-NA|country-Kenya|exactsite-NA|lat_-3.944|lon_39.774|elev-NA\n",
      ">KALG144-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Bostrychia|sp-Bostrychia radicans|subsp-NA|country-Kenya|exactsite-NA|lat_-3.944|lon_39.774|elev-NA\n",
      ">KALG145-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Bostrychia|sp-Bostrychia radicans|subsp-NA|country-Kenya|exactsite-NA|lat_-3.944|lon_39.774|elev-NA\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "sed -i 's/\"//g' idrck_headers.csv\n",
    "awk 'BEGIN{FS=\",\"; OFS=\"|\"}; NR == 1 { next }; { for(i=1; i<=NF; i++) if($i ~ /^ *$/) $i = \"NA\" }; {print \">\" $1, $2, $3, $4, \"fam-\"$5, \"subfam-\"$6, \"tri-\"$7, \"gs-\"$8, \"sp-\"$9, \"subsp-\"$10, \"country-\"$11, \"exactsite-\"$12, \"lat_\"$13, \"lon_\"$14, \"elev-\"$15}' idrck_headers.csv > idrck_headers.fasta\n",
    "ls idrck*\n",
    "head -10 idrck_headers.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing/Substituting Headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">KALG100-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora_spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      "TACTTTATACTTAATTTTTGGAGCTTTTTCTGGAATATTAGGAGGTTGTATGTCAATGTTAATTCGTATGGAATTGGCTCAGCCTGGTAATCAATTACTTTTAGGTAATCATCAAGTTTACAATGTTCTTATCACAGCCCACGCATTTTTAATGATATTTTTTATGGTTATGCCAGTGATGATCGGAGGTTTTGGTAATTGATTTGTACCTATTATGATAGGTAGTCCTGATATGGCATTCCCTCGATTAAATAATATTTCCTTTTGATTATTACCACCTTCATTATGTCTGTTATTATTATCATCCGTAGTAGAAGTAGGTACAGGTACAGGTTGAACTGTTTATCCTCCATTAAGTTCTATACAAAGTCATTCAGGAGCTTCTGTTGATTTAGCAATATTTAGTTTACATTTATCAGGAGCTTCCTCTATTCTAGGTGCAATTAATTTTATTTCTACAATATTAAATATGCGTAATCCTGGACAAACATTTTATAGAATTCCGTTATTTGTTTGGGCAATTTTTGTTACAGCATTTTTATTATTATTAGCAGTTCCAGTATTAGCAGGAGCGATAACAATGTTATTAACTGATAGGAATTTTAATACCTCTTTTTTTGATCCAGCAGGAGGTGGAGATCCTATTCTTTACCAACATTTATTT\n",
      ">KALG099-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora_spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n",
      "TACTTTATACTTAATTTTTGGAGCTTTTTCTGGAATATTAGGAGGTTGTATGTCAATGTTAATTCGTATGGAATTGGCTCAGCCTGGTAATCAATTACTTTTAGGTAATCATCAAGTTTACAATGTTCTTATCACAGCCCACGCATTTTTAATGATATTTTTTATGGTTATGCCAGTGATGATCGGAGGTTTTGGTAATTGATTTGTACCTATTATGATAGGTAGTCCTGATATGGCATTCCCTCGATTAAATAATATTTCCTTTTGATTATTACCACCTTCATTATGTCTGTTATTATTATCATCCGTAGTAGAAGTAGGTACAGGTACAGGTTGAACTGTTTATCCTCCATTAAGTTCTATACAAAGTCATTCAGGAGCTTCTGTTGATTTAGCAATATTTAGTTTACATTTATCAGGAGCTTCCTCTATTCTAGGTGCAATTAATTTTATTTCTACAATATTAAATATGCGTAATCCTGGACAAACATTTTATAGAATTCCGTTATTTGTTTGGGCAATTTTTGTTACAGCATTTTTATTATTATTAGCAGTTCCAGTATTAGCAGGAGCGATAACAATGTTATTAACTGATAGGAATTTTAATACCTCTTTTTTTGATCCAGCAGGAGGTGGAGATCCTATTCTTTACCAACATTTATTT\n",
      ">KALG098-10|Rhodophyta|Florideophyceae|Ceramiales|fam-Rhodomelaceae|subfam-NA|tri-NA|gs-Acanthophora|sp-Acanthophora_spicifera|subsp-NA|country-Kenya|exactsite-NA|lat_-4.26|lon_39.599|elev-NA\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "head -5 idrck.fasta # Before headers are replaced\n",
    ". ../../../../code/process_all_input_files.sh\n",
    "replacing_headers idrck.fasta << EOF\n",
    "./idrck_headers.fasta\n",
    "EOF\n",
    "head -5 idrck.fasta # After headers are replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.2 Working with:**  \n",
    "1. **GMTAH,GMTAI and GMTAJ:** (merged into Mpala_Kinondo_Turkana_Malaise_traps.fa) \n",
    "2. **DS-KENFRUIT**\n",
    "3. **DS-MPALALEP** and\n",
    "4. **DS-TBILE**  \n",
    "\n",
    "In the BOLDSystems database through my account I have access to the above projects. The merged dataset GMTAH-GMTAI-GMTAJ, DS-KENFRUIT and DS-MPALALEP are all not available publicly with the exception of DS-TBILE.  \n",
    "These unpublished dataset were dowloaded with permission from their respective data managers. Two files for each; a spreadsheet with all metadata (`*.xlsx`) and a sequences file (`*.fa`) whose headers were further edited as shown below:  \n",
    "The .fa files are the unedited FASTA format sequence files downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS-KENFRUIT_edit.fa\n",
      "DS-KENFRUIT.fa\n",
      "DS-KENFRUIT.fasta\n",
      "DS-KENFRUIT_headers\n",
      "DS-KENFRUIT.xlsx\n",
      "DS-MPALALEP_edit.fa\n",
      "DS-MPALALEP.fa\n",
      "DS-MPALALEP.fasta\n",
      "DS-MPALALEP_headers\n",
      "DS-MPALALEP.xlsx\n",
      "headers_edit.fasta\n",
      "idrck.fasta\n",
      "idrck_headers\n",
      "idrck_headers_all\n",
      "idrck_headers.csv\n",
      "idrck_headers.fasta\n",
      "idrck_orders\n",
      "idrck.xls\n",
      "Mpala_Kinondo_Turkana_Malaise_traps_edit.fa\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.fa\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.fasta\n",
      "Mpala_Kinondo_Turkana_Malaise_traps_insecta.fasta\n",
      "Mpala_Kinondo_Turkana_Malaise_traps_unedited.fasta\n",
      "Mpala_Kinondo_Turkana_Malaise_traps.xlsx\n",
      "Mpala_Kinondo_Turkana_tagged.xlsx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Editing the headers**  \n",
    "The headers in the \\*.fa files are not well formated by default. The look as shown below:  \n",
    ">\\>GMKMV173-15|Cicadellidae|Arthropoda|Insecta|Hemiptera|Cicadellidae||||||Kenya|Mpala Research Centre|0.293|36.899|1650.0\n",
    ">\\>PMANL5032-15|Sarrothripini|Arthropoda|Insecta|Lepidoptera|Nolidae|Chloephorinae|Sarrothripini||||Kenya|Muhaka Forest|-4.325|39.525|50.0 \n",
    "\n",
    "Editing these headers to standard like in the others before, deletes the default taxon and introduces prefices to the fields in the headers for easy understanding\n",
    "1. \"fam-\" for family taxon name\n",
    "2. \"subfam-\" for subfamily taxon name\n",
    "3. \"tri-\" for tribe taxon name\n",
    "4. \"gs-\" for genus taxon name\n",
    "5. \"sp-\" for species taxon name\n",
    "6. \"subsp-\" for subspecies taxon name\n",
    "7. \"country-\" for country of origin name\n",
    "8. \"exactsite-\" for exact site of origin name\n",
    "9. \"lat_\" for latitude co-ordinate\n",
    "10. \"lon_\" for longitude co-ordinate name\n",
    "11. \"elev-\" for elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "#Generating copies of the seq. files\n",
    "cp DS-KENFRUIT.fa DS-KENFRUIT_edit.fa\n",
    "cp DS-MPALALEP.fa DS-MPALALEP_edit.fa\n",
    "cp Mpala_Kinondo_Turkana_Malaise_traps.fa Mpala_Kinondo_Turkana_Malaise_traps_edit.fa\n",
    "\n",
    "source ../../../../code/process_all_input_files.sh\n",
    "for i in $(ls Mpala_Kinondo_Turkana_Malaise_traps_edit.fa); do grep \">\" $i | awk 'BEGIN {FS=\"|\"; OFS=\"|\"}; { for(i=1; i<=NF; i++) if($i ~ /^ *$/) $i = \"NA\" }; {print $1, $3, $4, $5, \"fam-\"$6, \"subfam-\"$7, \"tri-\"$8, \"gs-\"$9, \"sp-\"$10, \"subsp-\"$11, \"country-\"$12, \"exactsite-\"$13, \"lat_\"$14, \"lon_\"$15, \"elev-\"$16 }' > headers_edit.fasta; replacing_headers $i << EOF\n",
    "./headers_edit.fasta\n",
    "EOF\n",
    "done\n",
    "cp DS-KENFRUIT.fa DS-KENFRUIT.fasta\n",
    "cp DS-MPALALEP.fa DS-MPALALEP.fasta\n",
    "#cp Mpala_Kinondo_Turkana_Malaise_traps_edit.fa Mpala_Kinondo_Turkana_Malaise_traps.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Mpala_Kinondo_Turkana_Malaise_traps.fa**  \n",
    "This particular dataset has 37,856 records with varying sequence lenghths. An alignment of such a big dataset will not be good unless the data is subsetted* based on seqeunce length, aligned, cleaned and ultimately merged to make a good proper alignment.  \n",
    "This was done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "\n",
    "#creating a working copy\n",
    "cp Mpala_Kinondo_Turkana_Malaise_traps.fa input.fasta\n",
    "#removing gaps. The output is \"input_dgpd.fasta\", without gaps, \"-\".\n",
    "source ../../../../code/process_all_input_files.sh\n",
    "remove_gaps input.fasta\n",
    "#Introducing a field \"l-xxx\" that has the length of the sequence in the header\n",
    "awk '/^>/{hdr=$0; next}\n",
    "    { seq=$0 } match(seq,/^.*$/) { LEN=RLENGTH }\n",
    "    { print hdr\"|l-\"LEN; print seq }' input_dgpd.fasta > input_dgpd_edited.fasta\n",
    "\n",
    "mv input_dgpd_edited.fasta Mpala_Kinondo_Turkana_Malaise_traps.fasta\n",
    "\n",
    "#Understanding the taxonomic representation of the various orders\n",
    "awk 'BEGIN{FS=\"|\"}; /^>/{print $4}' Mpala_Kinondo_Turkana_Malaise_traps_all.fasta | sort | uniq -c | less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the taxonomic distripution of the many orders within Mpala_Kinondo_Turkana_Malaise_traps_all.fasta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phyla represented: \n",
      "  37846 Arthropoda\n",
      "     10 Mollusca\n",
      "\n",
      "Classes represented in Arthropoda phylum: \n",
      "    820 Arachnida\n",
      "    833 Collembola\n",
      "     52 Diplopoda\n",
      "  36136 Insecta\n",
      "      5 Malacostraca\n",
      "\n",
      "Orders represented in Insecta class: \n",
      "      1 Archaeognatha\n",
      "    232 Blattodea\n",
      "   2121 Coleoptera\n",
      "  17827 Diptera\n",
      "      1 Embioptera\n",
      "   3912 Hemiptera\n",
      "   8037 Hymenoptera\n",
      "   3301 Lepidoptera\n",
      "     25 Mantodea\n",
      "     10 Mecoptera\n",
      "     59 Neuroptera\n",
      "    175 Orthoptera\n",
      "    307 Psocodea\n",
      "    121 Thysanoptera\n",
      "      6 Trichoptera\n",
      "      1 Zygentoma\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "echo -e \"Phyla represented: \"\n",
    "awk 'BEGIN{FS=\"|\"}; /^>/{print $2}' Mpala_Kinondo_Turkana_Malaise_traps_all.fasta | sort | uniq -c | less\n",
    "echo -e \"\\nClasses represented in Arthropoda phylum: \"\n",
    "grep \"Arthropoda\"  Mpala_Kinondo_Turkana_Malaise_traps_all.fasta | awk 'BEGIN{FS=\"|\"}; /^>/{print $3}' | sort | uniq -c | less\n",
    "echo -e \"\\nOrders represented in Insecta class: \"\n",
    "grep \"Insecta\"  Mpala_Kinondo_Turkana_Malaise_traps_all.fasta | awk 'BEGIN{FS=\"|\"}; /^>/{print $4}' | sort | uniq -c | less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Mpala_Kinondo_Turkana_Malaise_traps.fasta into nucleotide length dependent files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/kibet/bioinformatics/github/co1_metaanalysis/data/input/input_data/unpublished/\n",
    "source ../../../../code/process_all_input_files.sh\n",
    "\n",
    "#Extracting records from Insecta class\n",
    "delete_unwanted Mpala_Kinondo_Turkana_Malaise_traps.fasta << EOF\n",
    "1\n",
    "Insecta\n",
    "2\n",
    "EOF\n",
    "\n",
    "#Splitting\n",
    "subset_seqs Mpala_Kinondo_Turkana_Malaise_traps_Insecta.fasta << EOF\n",
    "N\n",
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
